{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81cf344",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eba15a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8200f66f9c74c16ae06fb487c6361d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db6b8e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "#model_id = \"google/gemma-2b-it\"\n",
    "\n",
    "model_id = \"facebook/bart-large-mnli\"\n",
    "model_id = \"distilbert/distilgpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "device = 'cpu' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff01788",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    formatted_prompt = tokenizer.apply_chat_template(\n",
    "        chat,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3b8c5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] <<SYS>>\n",
      "You are an AI assistant.\n",
      "<</SYS>>[INST] Where is Paris? [/INST]\n",
      "<</SYS>>[INST] Where is Paris? [/INST]\n",
      "<</SYS>>[INST] Where is Paris? [/INST]\n",
      "<</SYS>>[INST] Where is Paris? [/INST]\n",
      "<</SYS>>[INST] Where is Paris? [/INST]\n",
      "<</SYS>>\n"
     ]
    }
   ],
   "source": [
    "def inference(question: str, context: str):\n",
    "\n",
    "    if context == None or context == \"\":\n",
    "        prompt = f\"\"\"Give a detailed answer to the following question. Question: {question}\"\"\"\n",
    "    else:\n",
    "        prompt = f\"\"\"Using the information contained in the context, give a detailed answer to the question.\n",
    "            Context: {context}.\n",
    "            Question: {question}\"\"\"\n",
    "    \n",
    "    system_prompt = \"You are an AI assistant.\"\n",
    "    formatted_prompt = f\"[INST] <<SYS>>\\n{system_prompt}\\n<</SYS>>[INST] {question} [/INST]\"\n",
    "    \n",
    "    tokenizer.padding_side = \"left\"\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    \n",
    "    inputs = tokenizer.encode(\n",
    "        formatted_prompt, add_special_tokens=False, return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs,\n",
    "            max_length=100\n",
    "            #max_new_tokens=250,\n",
    "            #do_sample=False,\n",
    "        )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    #response = response[len(formatted_prompt) :]  # remove input prompt from reponse\n",
    "    response = response.replace(\"<eos>\", \"\")  # remove eos token\n",
    "    return response\n",
    "\n",
    "\n",
    "question = \"Where is Paris?\"\n",
    "print(inference(question=question, context=\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b059be33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e175941a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'gemma:2b',\n",
       " 'created_at': '2024-05-22T02:41:02.0002534Z',\n",
       " 'response': 'A transformer is an electrical device that transfers energy from one circuit to another through induction. It is a passive device, meaning that it does not generate or consume electrical energy itself.\\n\\n**Key characteristics of a transformer:**\\n\\n* **Inductance:** The ability of a transformer to store and release energy in an alternating current circuit.\\n* **Voltage:** The amount of voltage supplied to the primary circuit.\\n* **Current:** The amount of current flowing through the primary and secondary circuits.\\n* **Power:** The rate at which energy is transferred from the primary to the secondary circuit.\\n* **Turns ratio:** The ratio of the number of turns in the primary to the number of turns in the secondary circuit.\\n\\n**How a transformer works:**\\n\\nA transformer works based on the principle of electromagnetic induction. When an alternating current is applied to the primary circuit, it creates a magnetic field. This magnetic field can induce an alternating current in the secondary circuit, even if there is no physical connection between the two circuits.\\n\\n**Applications of transformers:**\\n\\n* **Power distribution:** Transformers are used to distribute electricity from power plants to homes and businesses.\\n* **Communication:** Transformers are used in communication systems to increase or decrease the voltage of a signal.\\n* **Electronics:** Transformers are used in electronic devices, such as radios and computers.\\n* **Industrial applications:** Transformers are used in industrial machinery, such as motors and compressors.\\n\\n**Advantages of transformers:**\\n\\n* **High power ratings:** Transformers can handle large amounts of power.\\n* **High efficiency:** Transformers can transfer energy with high efficiency.\\n* **Isolation:** Transformers can isolate circuits from each other.',\n",
       " 'done': True,\n",
       " 'context': [106,\n",
       "  1645,\n",
       "  108,\n",
       "  1841,\n",
       "  603,\n",
       "  476,\n",
       "  46895,\n",
       "  235336,\n",
       "  107,\n",
       "  108,\n",
       "  106,\n",
       "  2516,\n",
       "  108,\n",
       "  235280,\n",
       "  46895,\n",
       "  603,\n",
       "  671,\n",
       "  16756,\n",
       "  6064,\n",
       "  674,\n",
       "  32363,\n",
       "  4134,\n",
       "  774,\n",
       "  974,\n",
       "  13341,\n",
       "  577,\n",
       "  2550,\n",
       "  1593,\n",
       "  33205,\n",
       "  235265,\n",
       "  1165,\n",
       "  603,\n",
       "  476,\n",
       "  30987,\n",
       "  6064,\n",
       "  235269,\n",
       "  6996,\n",
       "  674,\n",
       "  665,\n",
       "  1721,\n",
       "  780,\n",
       "  11941,\n",
       "  689,\n",
       "  35981,\n",
       "  16756,\n",
       "  4134,\n",
       "  5344,\n",
       "  235265,\n",
       "  109,\n",
       "  688,\n",
       "  2469,\n",
       "  10314,\n",
       "  576,\n",
       "  476,\n",
       "  46895,\n",
       "  66058,\n",
       "  109,\n",
       "  235287,\n",
       "  5231,\n",
       "  2230,\n",
       "  2421,\n",
       "  851,\n",
       "  66058,\n",
       "  714,\n",
       "  7374,\n",
       "  576,\n",
       "  476,\n",
       "  46895,\n",
       "  577,\n",
       "  4659,\n",
       "  578,\n",
       "  4236,\n",
       "  4134,\n",
       "  575,\n",
       "  671,\n",
       "  67420,\n",
       "  2474,\n",
       "  13341,\n",
       "  235265,\n",
       "  108,\n",
       "  235287,\n",
       "  5231,\n",
       "  67454,\n",
       "  66058,\n",
       "  714,\n",
       "  3619,\n",
       "  576,\n",
       "  14623,\n",
       "  18447,\n",
       "  577,\n",
       "  573,\n",
       "  7920,\n",
       "  13341,\n",
       "  235265,\n",
       "  108,\n",
       "  235287,\n",
       "  5231,\n",
       "  6846,\n",
       "  66058,\n",
       "  714,\n",
       "  3619,\n",
       "  576,\n",
       "  2474,\n",
       "  32866,\n",
       "  1593,\n",
       "  573,\n",
       "  7920,\n",
       "  578,\n",
       "  13752,\n",
       "  37451,\n",
       "  235265,\n",
       "  108,\n",
       "  235287,\n",
       "  5231,\n",
       "  10260,\n",
       "  66058,\n",
       "  714,\n",
       "  3974,\n",
       "  696,\n",
       "  948,\n",
       "  4134,\n",
       "  603,\n",
       "  21393,\n",
       "  774,\n",
       "  573,\n",
       "  7920,\n",
       "  577,\n",
       "  573,\n",
       "  13752,\n",
       "  13341,\n",
       "  235265,\n",
       "  108,\n",
       "  235287,\n",
       "  5231,\n",
       "  100396,\n",
       "  9537,\n",
       "  66058,\n",
       "  714,\n",
       "  9537,\n",
       "  576,\n",
       "  573,\n",
       "  1758,\n",
       "  576,\n",
       "  12722,\n",
       "  575,\n",
       "  573,\n",
       "  7920,\n",
       "  577,\n",
       "  573,\n",
       "  1758,\n",
       "  576,\n",
       "  12722,\n",
       "  575,\n",
       "  573,\n",
       "  13752,\n",
       "  13341,\n",
       "  235265,\n",
       "  109,\n",
       "  688,\n",
       "  2299,\n",
       "  476,\n",
       "  46895,\n",
       "  3598,\n",
       "  66058,\n",
       "  109,\n",
       "  235280,\n",
       "  46895,\n",
       "  3598,\n",
       "  3482,\n",
       "  611,\n",
       "  573,\n",
       "  12854,\n",
       "  576,\n",
       "  59714,\n",
       "  33205,\n",
       "  235265,\n",
       "  3194,\n",
       "  671,\n",
       "  67420,\n",
       "  2474,\n",
       "  603,\n",
       "  7936,\n",
       "  577,\n",
       "  573,\n",
       "  7920,\n",
       "  13341,\n",
       "  235269,\n",
       "  665,\n",
       "  18460,\n",
       "  476,\n",
       "  16472,\n",
       "  2725,\n",
       "  235265,\n",
       "  1417,\n",
       "  16472,\n",
       "  2725,\n",
       "  798,\n",
       "  37240,\n",
       "  671,\n",
       "  67420,\n",
       "  2474,\n",
       "  575,\n",
       "  573,\n",
       "  13752,\n",
       "  13341,\n",
       "  235269,\n",
       "  1693,\n",
       "  1013,\n",
       "  1104,\n",
       "  603,\n",
       "  793,\n",
       "  6915,\n",
       "  6653,\n",
       "  1865,\n",
       "  573,\n",
       "  1378,\n",
       "  37451,\n",
       "  235265,\n",
       "  109,\n",
       "  688,\n",
       "  35940,\n",
       "  576,\n",
       "  76581,\n",
       "  66058,\n",
       "  109,\n",
       "  235287,\n",
       "  5231,\n",
       "  10260,\n",
       "  7107,\n",
       "  66058,\n",
       "  128149,\n",
       "  708,\n",
       "  1671,\n",
       "  577,\n",
       "  37125,\n",
       "  19080,\n",
       "  774,\n",
       "  2384,\n",
       "  7652,\n",
       "  577,\n",
       "  11407,\n",
       "  578,\n",
       "  12065,\n",
       "  235265,\n",
       "  108,\n",
       "  235287,\n",
       "  5231,\n",
       "  46944,\n",
       "  66058,\n",
       "  128149,\n",
       "  708,\n",
       "  1671,\n",
       "  575,\n",
       "  9228,\n",
       "  5188,\n",
       "  577,\n",
       "  4740,\n",
       "  689,\n",
       "  16840,\n",
       "  573,\n",
       "  14623,\n",
       "  576,\n",
       "  476,\n",
       "  9402,\n",
       "  235265,\n",
       "  108,\n",
       "  235287,\n",
       "  5231,\n",
       "  122256,\n",
       "  66058,\n",
       "  128149,\n",
       "  708,\n",
       "  1671,\n",
       "  575,\n",
       "  16034,\n",
       "  9630,\n",
       "  235269,\n",
       "  1582,\n",
       "  685,\n",
       "  81110,\n",
       "  578,\n",
       "  25175,\n",
       "  235265,\n",
       "  108,\n",
       "  235287,\n",
       "  5231,\n",
       "  57000,\n",
       "  8557,\n",
       "  66058,\n",
       "  128149,\n",
       "  708,\n",
       "  1671,\n",
       "  575,\n",
       "  9365,\n",
       "  25491,\n",
       "  235269,\n",
       "  1582,\n",
       "  685,\n",
       "  35853,\n",
       "  578,\n",
       "  165320,\n",
       "  235265,\n",
       "  109,\n",
       "  688,\n",
       "  39857,\n",
       "  576,\n",
       "  76581,\n",
       "  66058,\n",
       "  109,\n",
       "  235287,\n",
       "  5231,\n",
       "  7978,\n",
       "  2384,\n",
       "  22658,\n",
       "  66058,\n",
       "  128149,\n",
       "  798,\n",
       "  6589,\n",
       "  2910,\n",
       "  15992,\n",
       "  576,\n",
       "  2384,\n",
       "  235265,\n",
       "  108,\n",
       "  235287,\n",
       "  5231,\n",
       "  7978,\n",
       "  12148,\n",
       "  66058,\n",
       "  128149,\n",
       "  798,\n",
       "  5853,\n",
       "  4134,\n",
       "  675,\n",
       "  1536,\n",
       "  12148,\n",
       "  235265,\n",
       "  108,\n",
       "  235287,\n",
       "  5231,\n",
       "  93539,\n",
       "  66058,\n",
       "  128149,\n",
       "  798,\n",
       "  53316,\n",
       "  37451,\n",
       "  774,\n",
       "  1853,\n",
       "  1156,\n",
       "  235265,\n",
       "  107,\n",
       "  108],\n",
       " 'total_duration': 57396397400,\n",
       " 'load_duration': 8093403300,\n",
       " 'prompt_eval_count': 14,\n",
       " 'prompt_eval_duration': 4087176000,\n",
       " 'eval_count': 338,\n",
       " 'eval_duration': 45195192000}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "ollama.generate(model='gemma:2b', prompt=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bbe0601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loaders = [\n",
    "    PyPDFLoader(\"files/LLMclinical.pdf\")\n",
    "]\n",
    "pages = []\n",
    "for loader in loaders:\n",
    "    pages.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d75aa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "text_splitter = TokenTextSplitter(chunk_size=128, chunk_overlap=12)\n",
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7666c6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elle Barral1, \n",
      "Christopher Semturs1, Alan Karthikesalingam1,5 ✉ & Vivek Natarajan1,5 ✉\n",
      "Large language models (LLMs) have demonstrated impressive capabilities, but the \n",
      "bar for clinical applications is high. Attempts to assess the clinical knowledge of \n",
      "models typically rely on automated evaluations based on limited benchmarks. Here, to address these limitations, we present MultiMedQA, a benchmark combining six \n",
      "existing medical question answering datasets spanning professional medicine, \n",
      "research and consumer queries and a new dataset of medical questions\n"
     ]
    }
   ],
   "source": [
    "print(docs[2].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "594f26cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from langchain_community.embeddings import (\n",
    "    HuggingFaceEmbeddings\n",
    ")\n",
    "encoder = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L12-v2', model_kwargs = {'device': \"cpu\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c15cfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02857219219547718\n"
     ]
    }
   ],
   "source": [
    "embeddings1 = encoder.embed_query(\"RAG\")\n",
    "embeddings2 = encoder.embed_query(docs[0].page_content)\n",
    "print(np.dot(embeddings1, embeddings2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e568eede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "faiss_db = FAISS.from_documents(docs, encoder, distance_strategy=DistanceStrategy.DOT_PRODUCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eea19f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and metadata: \n",
      "presence of labels or explanations and their sources. A summary of \n",
      "MultiMedQA is presented in Extended Data Table 1.\n",
      "Although MedMCQA, PubMedQA, LiveQA, and MedicationQA \n",
      "provide reference long-form answers or explanations, we do not use them in this work. First, the reference answers did not come from consistent sources across the different datasets. Answers \n",
      "often came from automated tools or non-clinicians such as librar -\n",
      "ians. The construction of the reference answers and explanations \n",
      "in these pioneering datasets was not\n",
      "\n",
      "MultiMedQA benchmark. MultiMedQA includes medical exams \n",
      "and research datasets with multiple-choice answers and consumer \n",
      "medical question datasets with long-form answers. These include the \n",
      "MedQA3, MedMCQA4, PubMedQA5, MMLU clinical topics6, LiveQA13 \n",
      "and MedicationQA14 datasets. We further augmented MultiMedQA  \n",
      "with a new dataset of curated commonly searched health queries: \n",
      "HealthSearchQA. All the datasets are in the English language and we \n",
      "describe them in detail below.\n",
      "These\n",
      " \n",
      "useful for improving factors related to accuracy, factuality, consistency, \n",
      "safety, harm and bias, helping to close the gap with clinical experts and \n",
      "bring these models closer to real-world clinical applications.\n",
      "Limitations\n",
      "Our study demonstrates the potential of LLMs for encoding medical \n",
      "knowledge and for answering medical questions. Below we discuss \n",
      "limitations and outline directions for future research.\n",
      "Expansion of MultiMedQA\n",
      "Although the MultiMedQA benchmark is diverse and contains ques -\n",
      "tions from a variety of medical exam, medical research and consumer \n",
      "sources, it is by\n",
      "Extended Data Table 1 | Summary of MultiMedQA describing the format, size, and domain of the datasets in the benchmark\n",
      "\n",
      "MedMCQA. The MedMCQA dataset4 consists of more than 194,000 \n",
      "four-option multiple-choice questions from Indian medical entrance \n",
      "examinations (AIIMS/NEET)4. This dataset covers 2,400 healthcare \n",
      "topics and 21 medical subjects. The development set is substantial, \n",
      "with over 187,000 questions.Format: Q + A, multiple choice, open domain.\n",
      "Size (dev/test): 187,000/6,100.\n",
      "Example question: Which of the following ultrasound findings has \n",
      "the highest association with aneuploidy\n",
      " and do not enable the detailed \n",
      "analysis required for real-world clinical applications. This creates an \n",
      "unmet need for a broad medical question-answering benchmark to \n",
      "assess LLMs for their response factuality, use of expert knowledge in \n",
      "reasoning, helpfulness, precision, health equity and potential harm.\n",
      "To address this, we curate MultiMedQA, a benchmark comprising \n",
      "seven medical question-answering datasets, including six existing data -\n",
      "sets: MedQA3, MedMCQA4, PubMedQA5, LiveQA13, MedicationQ\n",
      " between Med-PaLM’s responses to \n",
      "MultiMedQA consumer questions and the PaLM training corpus and \n",
      "observed no overlap. We also assessed the overlap between MultiMedQA \n",
      "multiple-choice questions and the training corpus, observing minimal a\n",
      "b&OLQLFLDQ0HG\u00103D/0)ODQ\u00103D/0\n",
      "&OLQLFLDQ0HG\u00103D/0)ODQ\u00103D/0\u001c",
      "\u0018\u0011\u001c",
      "\b\u001c",
      "\u0013\u0011\u001b\b\n",
      "\u001c",
      "\u0017\u0011\u0017\b$GGUHVV\u0003LQ\n",
      " context (Q + context + A). Whereas the MedQA and MedMCQA  \n",
      "datasets are open domain question-answering tasks, the PubMedQA \n",
      "task is closed domain, in that it requires answer inference from the \n",
      "supporting PubMed abstract context.Format: Q + context + A, multiple choice, closed domain.Size (development set/test set): 500/500.\n",
      "Example question: Double balloon enteroscopy (DBE): is it efficacious \n",
      "and safe in a community setting?Context: From March 2007 to January 2011, 88 DBE procedures were performed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"What is MultiMedQA?\"\n",
    "retrieved_docs = faiss_db.similarity_search(question, k=8)\n",
    "context = \"\".join(doc.page_content + \"\\n\" for doc in retrieved_docs)\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da022c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(inference(question=question, context=context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f70e00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(question: str, context: str):\n",
    "\n",
    "    if context == None or context == \"\":\n",
    "        prompt = f\"\"\"Give a detailed answer to the following question. Question: {question}\"\"\"\n",
    "    else:\n",
    "        prompt = f\"\"\"Using the information contained in the context, give a detailed answer to the question.\n",
    "            Context: {context}.\n",
    "            Question: {question}\"\"\"    \n",
    "    print(prompt)\n",
    "    response = ollama.generate(model='gemma:2b', prompt=prompt)\n",
    "   \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eba18260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'gemma:2b',\n",
       " 'created_at': '2024-05-22T04:51:26.2143812Z',\n",
       " 'response': '**MultiMedQA is a benchmark comprising seven medical question-answering datasets, including six existing datasets: MedQA3, MedMCQA4, PubMedQA5, LiveQA13, MedicationQA** between Med-PaLM’s responses to MultiMedQA consumer questions and the PaLM training corpus and observed no overlap.\\n\\n**Sources of Labels and Explanations**\\nThe context does not specify the sources of the labels and explanations for the datasets in the benchmark. Therefore, I cannot provide a detailed answer to this question from the context.',\n",
       " 'done': True,\n",
       " 'context': [106,\n",
       "  1645,\n",
       "  108,\n",
       "  15325,\n",
       "  573,\n",
       "  2113,\n",
       "  13614,\n",
       "  575,\n",
       "  573,\n",
       "  4807,\n",
       "  235269,\n",
       "  2734,\n",
       "  476,\n",
       "  11352,\n",
       "  3448,\n",
       "  577,\n",
       "  573,\n",
       "  2872,\n",
       "  235265,\n",
       "  108,\n",
       "  149,\n",
       "  2930,\n",
       "  235292,\n",
       "  139,\n",
       "  639,\n",
       "  29182,\n",
       "  235292,\n",
       "  235248,\n",
       "  108,\n",
       "  75589,\n",
       "  576,\n",
       "  17737,\n",
       "  689,\n",
       "  44353,\n",
       "  578,\n",
       "  1024,\n",
       "  8269,\n",
       "  235265,\n",
       "  586,\n",
       "  13367,\n",
       "  576,\n",
       "  235248,\n",
       "  108,\n",
       "  9886,\n",
       "  4567,\n",
       "  39213,\n",
       "  603,\n",
       "  7659,\n",
       "  575,\n",
       "  55148,\n",
       "  4145,\n",
       "  5707,\n",
       "  235248,\n",
       "  235274,\n",
       "  235265,\n",
       "  108,\n",
       "  18626,\n",
       "  2934,\n",
       "  9186,\n",
       "  39213,\n",
       "  235269,\n",
       "  74552,\n",
       "  39213,\n",
       "  235269,\n",
       "  11688,\n",
       "  39213,\n",
       "  235269,\n",
       "  578,\n",
       "  110831,\n",
       "  39213,\n",
       "  235248,\n",
       "  108,\n",
       "  50133,\n",
       "  6203,\n",
       "  1497,\n",
       "  235290,\n",
       "  961,\n",
       "  10523,\n",
       "  689,\n",
       "  44353,\n",
       "  235269,\n",
       "  783,\n",
       "  749,\n",
       "  780,\n",
       "  1281,\n",
       "  1174,\n",
       "  575,\n",
       "  736,\n",
       "  1160,\n",
       "  235265,\n",
       "  5563,\n",
       "  235269,\n",
       "  573,\n",
       "  6203,\n",
       "  10523,\n",
       "  1498,\n",
       "  780,\n",
       "  2063,\n",
       "  774,\n",
       "  14097,\n",
       "  8269,\n",
       "  4492,\n",
       "  573,\n",
       "  2167,\n",
       "  47927,\n",
       "  235265,\n",
       "  22500,\n",
       "  235248,\n",
       "  108,\n",
       "  59554,\n",
       "  3392,\n",
       "  774,\n",
       "  34177,\n",
       "  8112,\n",
       "  689,\n",
       "  2173,\n",
       "  235290,\n",
       "  27343,\n",
       "  13615,\n",
       "  1582,\n",
       "  685,\n",
       "  17299,\n",
       "  486,\n",
       "  728,\n",
       "  108,\n",
       "  10875,\n",
       "  235265,\n",
       "  714,\n",
       "  6584,\n",
       "  576,\n",
       "  573,\n",
       "  6203,\n",
       "  10523,\n",
       "  578,\n",
       "  44353,\n",
       "  235248,\n",
       "  108,\n",
       "  473,\n",
       "  1450,\n",
       "  97362,\n",
       "  47927,\n",
       "  729,\n",
       "  780,\n",
       "  109,\n",
       "  9886,\n",
       "  4567,\n",
       "  39213,\n",
       "  43408,\n",
       "  235265,\n",
       "  9530,\n",
       "  4567,\n",
       "  39213,\n",
       "  6566,\n",
       "  6910,\n",
       "  29550,\n",
       "  235248,\n",
       "  108,\n",
       "  639,\n",
       "  3679,\n",
       "  47927,\n",
       "  675,\n",
       "  6733,\n",
       "  235290,\n",
       "  21062,\n",
       "  10523,\n",
       "  578,\n",
       "  15630,\n",
       "  235248,\n",
       "  108,\n",
       "  30227,\n",
       "  2872,\n",
       "  47927,\n",
       "  675,\n",
       "  1497,\n",
       "  235290,\n",
       "  961,\n",
       "  10523,\n",
       "  235265,\n",
       "  3766,\n",
       "  3707,\n",
       "  573,\n",
       "  235248,\n",
       "  108,\n",
       "  4567,\n",
       "  39213,\n",
       "  235304,\n",
       "  235269,\n",
       "  2934,\n",
       "  9186,\n",
       "  39213,\n",
       "  235310,\n",
       "  235269,\n",
       "  74552,\n",
       "  39213,\n",
       "  235308,\n",
       "  235269,\n",
       "  595,\n",
       "  3939,\n",
       "  235327,\n",
       "  13324,\n",
       "  16254,\n",
       "  235318,\n",
       "  235269,\n",
       "  11688,\n",
       "  39213,\n",
       "  235274,\n",
       "  235304,\n",
       "  235248,\n",
       "  108,\n",
       "  639,\n",
       "  110831,\n",
       "  39213,\n",
       "  235274,\n",
       "  235310,\n",
       "  47927,\n",
       "  235265,\n",
       "  1448,\n",
       "  4024,\n",
       "  70962,\n",
       "  9530,\n",
       "  4567,\n",
       "  39213,\n",
       "  139,\n",
       "  108,\n",
       "  3041,\n",
       "  476,\n",
       "  888,\n",
       "  20884,\n",
       "  576,\n",
       "  93162,\n",
       "  17203,\n",
       "  23905,\n",
       "  2962,\n",
       "  33733,\n",
       "  235292,\n",
       "  235248,\n",
       "  108,\n",
       "  13010,\n",
       "  7025,\n",
       "  39213,\n",
       "  235265,\n",
       "  2262,\n",
       "  573,\n",
       "  47927,\n",
       "  708,\n",
       "  575,\n",
       "  573,\n",
       "  4645,\n",
       "  5255,\n",
       "  578,\n",
       "  783,\n",
       "  235248,\n",
       "  108,\n",
       "  15019,\n",
       "  1174,\n",
       "  575,\n",
       "  8637,\n",
       "  3582,\n",
       "  235265,\n",
       "  108,\n",
       "  8652,\n",
       "  108,\n",
       "  235248,\n",
       "  108,\n",
       "  112640,\n",
       "  604,\n",
       "  19031,\n",
       "  7549,\n",
       "  5678,\n",
       "  577,\n",
       "  14998,\n",
       "  235269,\n",
       "  2251,\n",
       "  765,\n",
       "  2150,\n",
       "  235269,\n",
       "  31724,\n",
       "  235269,\n",
       "  235248,\n",
       "  108,\n",
       "  61483,\n",
       "  235269,\n",
       "  14649,\n",
       "  578,\n",
       "  18282,\n",
       "  235269,\n",
       "  12393,\n",
       "  577,\n",
       "  3387,\n",
       "  573,\n",
       "  12485,\n",
       "  675,\n",
       "  13324,\n",
       "  12930,\n",
       "  578,\n",
       "  235248,\n",
       "  108,\n",
       "  40254,\n",
       "  1450,\n",
       "  5377,\n",
       "  13951,\n",
       "  577,\n",
       "  1879,\n",
       "  235290,\n",
       "  9097,\n",
       "  13324,\n",
       "  8557,\n",
       "  235265,\n",
       "  108,\n",
       "  47066,\n",
       "  108,\n",
       "  5906,\n",
       "  3320,\n",
       "  41052,\n",
       "  573,\n",
       "  5736,\n",
       "  576,\n",
       "  25599,\n",
       "  14816,\n",
       "  604,\n",
       "  27162,\n",
       "  6910,\n",
       "  235248,\n",
       "  108,\n",
       "  54466,\n",
       "  578,\n",
       "  604,\n",
       "  39534,\n",
       "  6910,\n",
       "  3920,\n",
       "  235265,\n",
       "  30641,\n",
       "  783,\n",
       "  9742,\n",
       "  235248,\n",
       "  108,\n",
       "  169022,\n",
       "  578,\n",
       "  24430,\n",
       "  16759,\n",
       "  604,\n",
       "  3936,\n",
       "  3679,\n",
       "  235265,\n",
       "  108,\n",
       "  69474,\n",
       "  576,\n",
       "  9530,\n",
       "  4567,\n",
       "  39213,\n",
       "  108,\n",
       "  18626,\n",
       "  573,\n",
       "  9530,\n",
       "  4567,\n",
       "  39213,\n",
       "  43408,\n",
       "  603,\n",
       "  16932,\n",
       "  578,\n",
       "  7744,\n",
       "  1856,\n",
       "  728,\n",
       "  108,\n",
       "  1078,\n",
       "  774,\n",
       "  476,\n",
       "  8080,\n",
       "  576,\n",
       "  6910,\n",
       "  7106,\n",
       "  235269,\n",
       "  6910,\n",
       "  3679,\n",
       "  578,\n",
       "  15630,\n",
       "  235248,\n",
       "  108,\n",
       "  46240,\n",
       "  235269,\n",
       "  665,\n",
       "  603,\n",
       "  731,\n",
       "  108,\n",
       "  49476,\n",
       "  4145,\n",
       "  5707,\n",
       "  235248,\n",
       "  235274,\n",
       "  1420,\n",
       "  13705,\n",
       "  576,\n",
       "  9530,\n",
       "  4567,\n",
       "  39213,\n",
       "  28969,\n",
       "  573,\n",
       "  5920,\n",
       "  235269,\n",
       "  2395,\n",
       "  235269,\n",
       "  578,\n",
       "  11988,\n",
       "  576,\n",
       "  573,\n",
       "  47927,\n",
       "  575,\n",
       "  573,\n",
       "  43408,\n",
       "  109,\n",
       "  4567,\n",
       "  9186,\n",
       "  39213,\n",
       "  235265,\n",
       "  714,\n",
       "  2934,\n",
       "  9186,\n",
       "  39213,\n",
       "  20884,\n",
       "  235310,\n",
       "  13569,\n",
       "  576,\n",
       "  978,\n",
       "  1178,\n",
       "  235248,\n",
       "  235274,\n",
       "  235315,\n",
       "  235310,\n",
       "  235269,\n",
       "  235276,\n",
       "  235276,\n",
       "  235276,\n",
       "  235248,\n",
       "  108,\n",
       "  14806,\n",
       "  235290,\n",
       "  4071,\n",
       "  6733,\n",
       "  235290,\n",
       "  21062,\n",
       "  3920,\n",
       "  774,\n",
       "  6481,\n",
       "  6910,\n",
       "  16277,\n",
       "  235248,\n",
       "  108,\n",
       "  770,\n",
       "  4534,\n",
       "  903,\n",
       "  591,\n",
       "  11716,\n",
       "  45684,\n",
       "  235283,\n",
       "  210360,\n",
       "  235275,\n",
       "  235310,\n",
       "  235265,\n",
       "  1417,\n",
       "  20884,\n",
       "  14979,\n",
       "  235248,\n",
       "  235284,\n",
       "  235269,\n",
       "  235310,\n",
       "  235276,\n",
       "  235276,\n",
       "  22908,\n",
       "  235248,\n",
       "  108,\n",
       "  54611,\n",
       "  578,\n",
       "  235248,\n",
       "  235284,\n",
       "  235274,\n",
       "  6910,\n",
       "  12749,\n",
       "  235265,\n",
       "  714,\n",
       "  3505,\n",
       "  1142,\n",
       "  603,\n",
       "  18525,\n",
       "  235269,\n",
       "  235248,\n",
       "  108,\n",
       "  3041,\n",
       "  1163,\n",
       "  235248,\n",
       "  235274,\n",
       "  235321,\n",
       "  235324,\n",
       "  235269,\n",
       "  235276,\n",
       "  235276,\n",
       "  235276,\n",
       "  3920,\n",
       "  235265,\n",
       "  5699,\n",
       "  235292,\n",
       "  1274,\n",
       "  963,\n",
       "  586,\n",
       "  235269,\n",
       "  6733,\n",
       "  6241,\n",
       "  235269,\n",
       "  2174,\n",
       "  11988,\n",
       "  235265,\n",
       "  108,\n",
       "  2542,\n",
       "  591,\n",
       "  4903,\n",
       "  235283,\n",
       "  2195,\n",
       "  1245,\n",
       "  235248,\n",
       "  235274,\n",
       "  235321,\n",
       "  235324,\n",
       "  235269,\n",
       "  235276,\n",
       "  235276,\n",
       "  235276,\n",
       "  235283,\n",
       "  235318,\n",
       "  235269,\n",
       "  235274,\n",
       "  235276,\n",
       "  235276,\n",
       "  235265,\n",
       "  108,\n",
       "  8036,\n",
       "  2872,\n",
       "  235292,\n",
       "  12236,\n",
       "  576,\n",
       "  573,\n",
       "  2412,\n",
       "  66391,\n",
       "  14352,\n",
       "  919,\n",
       "  235248,\n",
       "  108,\n",
       "  1175,\n",
       "  9393,\n",
       "  14329,\n",
       "  675,\n",
       "  29633,\n",
       "  234289,\n",
       "  27142,\n",
       "  108,\n",
       "  578,\n",
       "  749,\n",
       "  780,\n",
       "  11321,\n",
       "  573,\n",
       "  11352,\n",
       "  235248,\n",
       "  108,\n",
       "  26413,\n",
       "  3690,\n",
       "  604,\n",
       "  1879,\n",
       "  235290,\n",
       "  9097,\n",
       "  13324,\n",
       "  8557,\n",
       "  235265,\n",
       "  1417,\n",
       "  18460,\n",
       "  671,\n",
       "  235248,\n",
       "  108,\n",
       "  549,\n",
       "  3150,\n",
       "  1476,\n",
       "  604,\n",
       "  476,\n",
       "  7209,\n",
       "  6910,\n",
       "  2872,\n",
       "  235290,\n",
       "  13072,\n",
       "  574,\n",
       "  43408,\n",
       "  577,\n",
       "  235248,\n",
       "  108,\n",
       "  113075,\n",
       "  25599,\n",
       "  14816,\n",
       "  604,\n",
       "  1024,\n",
       "  3590,\n",
       "  2251,\n",
       "  765,\n",
       "  2150,\n",
       "  235269,\n",
       "  1281,\n",
       "  576,\n",
       "  13865,\n",
       "  5567,\n",
       "  575,\n",
       "  235248,\n",
       "  108,\n",
       "  21248,\n",
       "  574,\n",
       "  235269,\n",
       "  10055,\n",
       "  1746,\n",
       "  235269,\n",
       "  21342,\n",
       "  235269,\n",
       "  2962,\n",
       "  23505,\n",
       "  578,\n",
       "  5736,\n",
       "  14649,\n",
       "  235265,\n",
       "  108,\n",
       "  1469,\n",
       "  3986,\n",
       "  736,\n",
       "  235269,\n",
       "  783,\n",
       "  156459,\n",
       "  9530,\n",
       "  4567,\n",
       "  39213,\n",
       "  235269,\n",
       "  476,\n",
       "  43408,\n",
       "  36087,\n",
       "  235248,\n",
       "  108,\n",
       "  31033,\n",
       "  6910,\n",
       "  2872,\n",
       "  235290,\n",
       "  13072,\n",
       "  574,\n",
       "  47927,\n",
       "  235269,\n",
       "  3359,\n",
       "  4442,\n",
       "  7881,\n",
       "  1423,\n",
       "  728,\n",
       "  108,\n",
       "  4607,\n",
       "  235292,\n",
       "  2934,\n",
       "  39213,\n",
       "  235304,\n",
       "  235269,\n",
       "  2934,\n",
       "  9186,\n",
       "  39213,\n",
       "  235310,\n",
       "  235269,\n",
       "  74552,\n",
       "  39213,\n",
       "  235308,\n",
       "  235269,\n",
       "  11688,\n",
       "  39213,\n",
       "  235274,\n",
       "  235304,\n",
       "  235269,\n",
       "  110831,\n",
       "  235368,\n",
       "  108,\n",
       "  1865,\n",
       "  2934,\n",
       "  235290,\n",
       "  5064,\n",
       "  18622,\n",
       "  235349,\n",
       "  235256,\n",
       "  15641,\n",
       "  577,\n",
       "  235248,\n",
       "  108,\n",
       "  9886,\n",
       "  4567,\n",
       "  39213,\n",
       "  15630,\n",
       "  3920,\n",
       "  578,\n",
       "  573,\n",
       "  3029,\n",
       "  18622,\n",
       "  4770,\n",
       "  50202,\n",
       "  578,\n",
       "  235248,\n",
       "  108,\n",
       "  93654,\n",
       "  793,\n",
       "  40768,\n",
       "  235265,\n",
       "  1448,\n",
       "  1170,\n",
       "  28234,\n",
       "  573,\n",
       "  40768,\n",
       "  1865,\n",
       "  9530,\n",
       "  4567,\n",
       "  39213,\n",
       "  235248,\n",
       "  108,\n",
       "  38571,\n",
       "  235290,\n",
       "  21062,\n",
       "  3920,\n",
       "  578,\n",
       "  573,\n",
       "  4770,\n",
       "  50202,\n",
       "  235269,\n",
       "  45715,\n",
       "  14426,\n",
       "  476,\n",
       "  108,\n",
       "  235268,\n",
       "  235343,\n",
       "  1967,\n",
       "  5811,\n",
       "  6282,\n",
       "  75471,\n",
       "  235276,\n",
       "  40404,\n",
       "  248775,\n",
       "  235304,\n",
       "  235299,\n",
       "  235283,\n",
       "  235276,\n",
       "  235275,\n",
       "  2120,\n",
       "  235368,\n",
       "  248775,\n",
       "  235304,\n",
       "  235299,\n",
       "  235283,\n",
       "  235276,\n",
       "  108,\n",
       "  235343,\n",
       "  1967,\n",
       "  5811,\n",
       "  6282,\n",
       "  75471,\n",
       "  235276,\n",
       "  40404,\n",
       "  248775,\n",
       "  235304,\n",
       "  235299,\n",
       "  235283,\n",
       "  235276,\n",
       "  235275,\n",
       "  2120,\n",
       "  235368,\n",
       "  248775,\n",
       "  235304,\n",
       "  235299,\n",
       "  235283,\n",
       "  235276,\n",
       "  255818,\n",
       "  250600,\n",
       "  253614,\n",
       "  255818,\n",
       "  245584,\n",
       "  255818,\n",
       "  252752,\n",
       "  253614,\n",
       "  242385,\n",
       "  245584,\n",
       "  108,\n",
       "  255818,\n",
       "  240,\n",
       "  253614,\n",
       "  240,\n",
       "  245584,\n",
       "  235323,\n",
       "  14798,\n",
       "  56225,\n",
       "  52757,\n",
       "  249006,\n",
       "  123552,\n",
       "  108,\n",
       "  4807,\n",
       "  591,\n",
       "  235368,\n",
       "  963,\n",
       "  4807,\n",
       "  963,\n",
       "  586,\n",
       "  846,\n",
       "  64232,\n",
       "  573,\n",
       "  2934,\n",
       "  39213,\n",
       "  578,\n",
       "  2934,\n",
       "  9186,\n",
       "  39213,\n",
       "  139,\n",
       "  108,\n",
       "  58106,\n",
       "  708,\n",
       "  2174,\n",
       "  11988,\n",
       "  2872,\n",
       "  235290,\n",
       "  13072,\n",
       "  574,\n",
       "  13333,\n",
       "  235269,\n",
       "  573,\n",
       "  74552,\n",
       "  39213,\n",
       "  235248,\n",
       "  108,\n",
       "  8277,\n",
       "  603,\n",
       "  7337,\n",
       "  11988,\n",
       "  235269,\n",
       "  575,\n",
       "  674,\n",
       "  665,\n",
       "  9286,\n",
       "  3448,\n",
       "  46540,\n",
       "  774,\n",
       "  573,\n",
       "  235248,\n",
       "  108,\n",
       "  118086,\n",
       "  74552,\n",
       "  9949,\n",
       "  4807,\n",
       "  235265,\n",
       "  5699,\n",
       "  235292,\n",
       "  1274,\n",
       "  963,\n",
       "  4807,\n",
       "  963,\n",
       "  586,\n",
       "  235269,\n",
       "  6733,\n",
       "  6241,\n",
       "  235269,\n",
       "  7337,\n",
       "  11988,\n",
       "  235265,\n",
       "  2542,\n",
       "  591,\n",
       "  30588,\n",
       "  1142,\n",
       "  235283,\n",
       "  2195,\n",
       "  1142,\n",
       "  1245,\n",
       "  235248,\n",
       "  235308,\n",
       "  235276,\n",
       "  235276,\n",
       "  235283,\n",
       "  235308,\n",
       "  235276,\n",
       "  235276,\n",
       "  235265,\n",
       "  108,\n",
       "  8036,\n",
       "  2872,\n",
       "  235292,\n",
       "  12510,\n",
       "  36977,\n",
       "  3343,\n",
       "  111601,\n",
       "  591,\n",
       "  4994,\n",
       "  235291,\n",
       "  1245,\n",
       "  603,\n",
       "  665,\n",
       "  205047,\n",
       "  235248,\n",
       "  108,\n",
       "  639,\n",
       "  5985,\n",
       "  575,\n",
       "  476,\n",
       "  4159,\n",
       "  7708,\n",
       "  235336,\n",
       "  2930,\n",
       "  235292,\n",
       "  4845,\n",
       "  4482,\n",
       "  235248,\n",
       "  235284,\n",
       "  235276,\n",
       "  235276,\n",
       "  235324,\n",
       "  577,\n",
       "  5468,\n",
       "  235248,\n",
       "  235284,\n",
       "  235276,\n",
       "  235274,\n",
       "  235274,\n",
       "  235269,\n",
       "  235248,\n",
       "  235321,\n",
       "  235321,\n",
       "  608,\n",
       "  7434,\n",
       "  12410,\n",
       "  1049,\n",
       "  8261,\n",
       "  108,\n",
       "  235265,\n",
       "  108,\n",
       "  149,\n",
       "  9413,\n",
       "  235292,\n",
       "  2439,\n",
       "  603,\n",
       "  9530,\n",
       "  4567,\n",
       "  39213,\n",
       "  235336,\n",
       "  107,\n",
       "  108,\n",
       "  106,\n",
       "  2516,\n",
       "  108,\n",
       "  688,\n",
       "  9886,\n",
       "  4567,\n",
       "  39213,\n",
       "  603,\n",
       "  476,\n",
       "  43408,\n",
       "  36087,\n",
       "  6861,\n",
       "  6910,\n",
       "  2872,\n",
       "  235290,\n",
       "  13072,\n",
       "  574,\n",
       "  47927,\n",
       "  235269,\n",
       "  3359,\n",
       "  4442,\n",
       "  7881,\n",
       "  47927,\n",
       "  235292,\n",
       "  2934,\n",
       "  39213,\n",
       "  235304,\n",
       "  235269,\n",
       "  2934,\n",
       "  9186,\n",
       "  39213,\n",
       "  235310,\n",
       "  235269,\n",
       "  74552,\n",
       "  39213,\n",
       "  235308,\n",
       "  235269,\n",
       "  11688,\n",
       "  39213,\n",
       "  235274,\n",
       "  235304,\n",
       "  235269,\n",
       "  110831,\n",
       "  39213,\n",
       "  688,\n",
       "  1865,\n",
       "  2934,\n",
       "  235290,\n",
       "  5064,\n",
       "  18622,\n",
       "  235349,\n",
       "  235256,\n",
       "  15641,\n",
       "  577,\n",
       "  9530,\n",
       "  4567,\n",
       "  39213,\n",
       "  15630,\n",
       "  3920,\n",
       "  578,\n",
       "  573,\n",
       "  ...],\n",
       " 'total_duration': 153668688900,\n",
       " 'load_duration': 13144800,\n",
       " 'prompt_eval_count': 918,\n",
       " 'prompt_eval_duration': 136679940000,\n",
       " 'eval_count': 112,\n",
       " 'eval_duration': 16964688000}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5dd598",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For this answer I used the following documents:\")\n",
    "for doc in retrieved_docs:\n",
    "    print(doc.metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
